sg.gene.pair.list, sep = "/n",
row.names = FALSE, col.names = FALSE)
}
# Chunk 1
rm(list=ls())  # clean up workspace
library(biomaRt)
# TO install
#source("https://bioconductor.org/biocLite.R")
#biocLite("biomaRt")
mart <- useMart("ensembl")
datasets <- listDatasets(mart)
# Here are the datasets for the selected species
selected.datasets <- c("hsapiens_gene_ensembl",        # Homo sapiens (Human)
"ptroglodytes_gene_ensembl",    # Pan troglodytes (Chimpanzee)
"ggorilla_gene_ensembl",        # Gorilla gorilla (Gorilla)
"pabelii_gene_ensembl",         # Pongo abelii (Orangutan)
"nleucogenys_gene_ensembl",     # Nomascus leucogenys (Gibbon)
"csabaeus_gene_ensembl",        # Chlorocebus sabaeus (Vervet-AGM)
"panubis_gene_ensembl",         # Papio anubis (Olive Baboon)
"mmulatta_gene_ensembl",        # Macaca mulatta (Macaque)
"tsyrichta_gene_ensembl",       # Tarsius syrichta (Tarsier)
"mmurinus_gene_ensembl",        # Microcebus murinus (Mouse Lemur)
"ogarnettii_gene_ensembl",      # Otolemur garnettii (Bushbaby)
"mmusculus_gene_ensembl",       # Mus musculus (Mouse)
"tbelangeri_gene_ensembl"       # Tupaia belangeri (Tree Threw)
)
spe.mart <- useDataset(selected.datasets[1],mart)
listFilters(spe.mart)
getBM(attributes=
c(# Chimpanzee
"ptroglodytes_homolog_ensembl_gene", "ptroglodytes_homolog_chromosome", "ptroglodytes_homolog_chrom_start", "ptroglodytes_homolog_chrom_end",
# Gorilla
"ggorilla_homolog_ensembl_gene", "ggorilla_homolog_chromosome", "ggorilla_homolog_chrom_start", "ggorilla_homolog_chrom_end",
# Orangutan
"pabelii_homolog_ensembl_gene", "pabelii_homolog_chromosome", "pabelii_homolog_chrom_start", "pabelii_homolog_chrom_end",
# Gibbon
"nleucogenys_homolog_ensembl_gene", "nleucogenys_homolog_chromosome", "nleucogenys_homolog_chrom_start", "nleucogenys_homolog_chrom_end"
),
filters = c('external_gene_name'),
values = "ADH1C", mart = spe.mart)
### Ensembl id for Human ADH1 genes
# ENSG00000187758   ADH1A
# ENSG00000196616   ADH1B
# ENSG00000248144   ADH1C
# Chunk 1
rm(list=ls())  # clean up workspace
setwd("/Users/Xiang/GitFolders/ADH1Genes/Code/")
seq.case <- "all_exon"
top.case <- "P1"
d1 <- 0
P1.summary.mat <- NULL
for(d2 in 0:1){
for(d3 in 0:2){
for(d4 in 0:3){
for(l1 in 0:2){
dup.los.case <- paste("D", paste(as.character(c(d2, d3, d4)), collapse = ""),
"L", as.character(l1), sep = "")
summary.file.name <- paste(top.case, "ADH1", seq.case, dup.los.case,
"summary.txt", sep = "_")
summary_file <- paste("./summary/", summary.file.name, sep = "")
all <- readLines(summary_file, n = -1)
row.names <- strsplit(all[length(all)], ' ')[[1]][-1]
summary_mat <- as.matrix(read.table(summary_file,
row.names = row.names,
col.names = dup.los.case))
#         assign(paste(top.case, "ADH1", seq.case, dup.los.case,
#                      "summary", sep = "_"), summary_mat)
P1.summary.mat <- cbind(P1.summary.mat, summary_mat)
}
}
}
}
top.case <- "Test"
Test.summary.mat <- NULL
for(d2 in 0:1){
for(d3 in 0:2){
for(d4 in 0:3){
for(l1 in 0:2){
dup.los.case <- paste("D", paste(as.character(c(d2, d3, d4)), collapse = ""),
"L", as.character(l1), sep = "")
summary.file.name <- paste(top.case, "ADH1", seq.case, dup.los.case,
"summary.txt", sep = "_")
summary_file <- paste("./summary/", summary.file.name, sep = "")
all <- readLines(summary_file, n = -1)
row.names <- strsplit(all[length(all)], ' ')[[1]][-1]
summary_mat <- as.matrix(read.table(summary_file,
row.names = row.names,
col.names = dup.los.case))
#         assign(paste(top.case, "ADH1", seq.case, dup.los.case,
#                      "summary", sep = "_"), summary_mat)
Test.summary.mat <- cbind(Test.summary.mat, summary_mat)
}
}
}
}
# Chunk 1
rm(list=ls())  # clean up workspace
#setwd("/Users/Xiang/GitFolders/ADH1Genes/Code/")
seq.case <- "all_exon"
top.case <- "P1"
d1 <- 0
P1.summary.mat <- NULL
Force.P1.summary.mat <- NULL
for(d2 in 0:1){
for(d3 in 0:2){
for(d4 in 0:3){
for(l1 in 0:3){
dup.los.case <- paste("D", paste(as.character(c(d2, d3, d4)), collapse = ""),
"L", as.character(l1), sep = "")
summary.file.name <- paste(top.case, "ADH1", seq.case, dup.los.case,
"summary.txt", sep = "_")
summary_file <- paste("./summary/", summary.file.name, sep = "")
all <- readLines(summary_file, n = -1)
row.names <- strsplit(all[length(all)], ' ')[[1]][-1]
summary_mat <- as.matrix(read.table(summary_file,
row.names = row.names,
col.names = dup.los.case))
#         assign(paste(top.case, "ADH1", seq.case, dup.los.case,
#                      "summary", sep = "_"), summary_mat)
length(summary_mat) <- 61
P1.summary.mat <- cbind(P1.summary.mat, summary_mat)
summary.file.name <- paste("Force", top.case, "ADH1", seq.case, dup.los.case,
"summary.txt", sep = "_")
summary_file <- paste("./summary/", summary.file.name, sep = "")
all <- readLines(summary_file, n = -1)
row.names <- strsplit(all[length(all)], ' ')[[1]][-1]
summary_mat <- as.matrix(read.table(summary_file,
row.names = row.names,
col.names = dup.los.case))
#         assign(paste(top.case, "ADH1", seq.case, dup.los.case,
#                      "summary", sep = "_"), summary_mat)
length(summary_mat) <- 61
Force.P1.summary.mat <- cbind(Force.P1.summary.mat, summary_mat)
}
}
}
}
top.case <- "Test"
Test.summary.mat <- NULL
for(d2 in 0:1){
for(d3 in 0:2){
for(d4 in 0:3){
for(l1 in 0:3){
dup.los.case <- paste("D", paste(as.character(c(d2, d3, d4)), collapse = ""),
"L", as.character(l1), sep = "")
summary.file.name <- paste(top.case, "ADH1", seq.case, dup.los.case,
"summary.txt", sep = "_")
summary_file <- paste("./summary/", summary.file.name, sep = "")
all <- readLines(summary_file, n = -1)
row.names <- strsplit(all[length(all)], ' ')[[1]][-1]
summary_mat <- as.matrix(read.table(summary_file,
row.names = row.names,
col.names = dup.los.case))
#         assign(paste(top.case, "ADH1", seq.case, dup.los.case,
#                      "summary", sep = "_"), summary_mat)
Test.summary.mat <- cbind(Test.summary.mat, summary_mat)
}
}
}
}
save.image(file = "ADH1.RData")
# Chunk 2
plot(Test.summary.mat["ll", ])
axis(side = 1, at = seq(4, 96, 4))
# Now show column names
colnames(Test.summary.mat)
plot(P1.summary.mat["ll",])
axis(side = 1, at = seq(4, 96, 4))
# Now show column names
colnames(P1.summary.mat)
# Chunk 1
rm(list=ls())  # clean up workspace
#' MM algorithm for smooth LAD regression
#'
#' @param X design matrix
#' @param y response
#' @param epsilon smoothing parameter
#' @param max_iter maximum number of iterations
#' @param tol convergence tolerance
smLAD <- function(X,y,epsilon=0.25,max_iter=1e2,tol=1e-3) {
# First, design matrix X should have same number of rows as Y
stopifnot(dim(X)[1] == dim(y)[1])
old.beta <- matrix(0.0, dim(X)[2], 1)
old.fx <- fx_LAD(X, y, old.beta, epsilon)
fx.values <- c(old.fx)
delta.fx.values <- NULL
delta.beta.values <- NULL
for(iter.num in 1:max_iter){
W <- 1.0 / sqrt((y - X %*% old.beta)^2 + epsilon)
new.beta <- solve(crossprod(X, as.vector(W) * X), crossprod(X, as.vector(W) * y))
new.fx <- fx_LAD(X, y, new.beta, epsilon)
fx.values <- c(fx.values, new.fx)
delta.fx <- old.fx - new.fx
delta.fx.values <- c(delta.fx.values, delta.fx)
delta.beta.values <- c(delta.beta.values, norm(new.beta - old.beta, "2"))
if( delta.fx < tol){
return(list(beta = new.beta, fx.values = fx.values, delta.fx.values = delta.fx.values,
delta.beta.values = delta.beta.values))
}
old.beta <- new.beta
old.fx <- new.fx
}
warning("Max iterations reached!")
return(list(beta = new.beta, fx.values = fx.values, delta.fx.values = delta.fx.values,
delta.beta.values = delta.beta.values))
}
#' Objective function of smooth LAD regression
#'
#' @param X design matrix
#' @param y response
#' @param beta parameter
#' @param epsilon smoothing parameter
fx_LAD <- function(X,y, beta, epsilon=0.25) {
return(sum(sqrt((y - X %*% beta)^2 + epsilon)))
}
# Chunk 2
## Number of International Calls from Belgium,
## taken from the Belgian Statistical Survey,
## published by the Ministry of Economy,
##
## 73 subjects, 2 variables:
##  Year(x[i])
##  Number of Calls (y[i], in tens of millions)
##
## http://www.uni-koeln.de/themen/statistik/data/rousseeuw/
## Datasets used in Robust Regression and Outlier Detection (Rousseeuw and Leroy, 1986).
## Provided on-line at the University of Cologne.
library(xji3ST790)
x <- c(50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
69, 70, 71, 72, 73)
y <- c(0.44, 0.47, 0.47, 0.59, 0.66, 0.73, 0.81, 0.88, 1.06, 1.20, 1.35, 1.49, 1.61,
2.12, 11.90, 12.40, 14.20, 15.90, 18.20, 21.20, 4.30, 2.40, 2.70, 2.90)
epsilon <- 0.25
X <- cbind(rep(1, length(x)), x)
fit.smLAD <- smLAD(X, y)
fit.lm <- lm(y ~ X)
fitted.lm <- fit.lm$fitted.values
fitted.smLAD <- X %*% fit.smLAD$beta
# Now plot the two fitted lines and data
plot(x, y, type = "l", col = "blue", main = "Step 2 plot")
lines(x, fitted.lm, lty = 2, col = "green")
lines(x, fitted.smLAD, lty = 3, col = "red")
legend(x[1], 20,legend = c("Data", "Least Sqaure", "smLAD"),
lty = c(1, 2, 3), col = c("blue", "green", "red"))
# Chunk 3
plot(fit.smLAD$fx.values, xlab = "k", ylab = "fx_smLAD", main = "Step 3 plot")
# Chunk 4
rm(list=ls())  # clean up workspace
#' Compute Newton Step (Naive) for logistic ridge regression
#'
#' @param X Design matrix
#' @param y Binary response vector
#' @param beta Current regression vector estimate
#' @param g Gradient vector
#' @param lambda Regularization parameter
newton_step_naive <- function(X, y, beta, g, lambda) {
X <- as.matrix(X)
X.beta <- X %*% beta
exp.X.beta <- exp(X.beta)
W <- exp.X.beta / (exp.X.beta + 1)^2
A <- lambda*diag(rep(dim(X)[2]))+crossprod(X, as.vector(W) * X)
L.t <- chol(A)
Lt.x <- forwardsolve(t(L.t), g)
delta.beta.nt <- backsolve(L.t, Lt.x)
return(delta.beta.nt)
}
# Chunk 5
#' Compute Newton Step (Sherman-Morrison-Woodbury) for logistic ridge regression
#'
#' @param X Design matrix
#' @param y Binary response vector
#' @param beta Current regression vector estimate
#' @param g Gradient vector
#' @param lambda Regularization parameter
newton_step_smw <- function(X, y, beta, g, lambda) {
X <- as.matrix(X)
X.beta <- X %*% beta
exp.X.beta <- exp(X.beta)
W.sqrt <- sqrt(exp.X.beta) / (exp.X.beta + 1)
V <- as.vector(W.sqrt) * X
C <- diag(rep(dim(X)[1])) + tcrossprod(V, V) / lambda
B.inv <- diag(rep(dim(X)[2])) / lambda - 1 / lambda^2 * crossprod(V, solve(C, V))
return(B.inv %*% g)
}
# Chunk 6
#' Backtracking for steepest descent
#'
#' @param fx handle to function that returns objective function values
#' @param x current parameter estimate
#' @param t current step-size
#' @param df the value of the gradient of objective function evaluated at the current x
#' @param d descent direction vector
#' @param alpha the backtracking parameter
#' @param beta the decrementing multiplier
backtrack_descent <- function(fx, x, t, df, d, alpha=0.5, beta=0.9, max.iter = 1e3) {
old.func.value <- fx(x)
tk <- t
for (num.iter in 1:max.iter){
new.x <- x - tk * d
new.func.value <- fx(new.x)
if(new.func.value < old.func.value -alpha * tk * crossprod(df, d)){
return(tk)
}else{
tk <- beta * tk
}
}
warning("Backtrack step search reaches max iterations!
Try increase max_iteration for backtrack function.")
return(tk)
}
# Chunk 7
#' Damped Newton's Method for Fitting Ridge Logistic Regression
#'
#' @param y Binary response
#' @param X Design matrix
#' @param beta Initial regression coefficient vector
#' @param lambda regularization parameter
#' @param max_iter maximum number of iterations
#' @param tol convergence tolerance
logistic_ridge_newton <- function(X, y, beta, lambda=0, max_iter=1e2, tol=1e-3, method = "naive") {
fx <- partial(fx_logistic, y = y, X = X)
df <- partial(gradf_logistic, y = y, X = X)
old.beta <- beta
g <- df(old.beta)
t <- 4.0 / norm(X, type = "2") ^ 2
if(method == "smw"){
newton_step_handle = newton_step_smw
}
else{
newton_step_handle = newton_step_naive
}
for (num.iter in 1:max_iter){
delta.x.nt <- newton_step_handle(X, y, old.beta, g, lambda)
decrement <- crossprod(g, delta.x.nt)
if (0.5 * decrement < tol){
return(list(beta = old.beta, num.iter = num.iter))
}else{
tk <- backtrack_descent(fx, old.beta, t, g, delta.x.nt, 0.5, 0.9)
old.beta <- old.beta - tk * delta.x.nt
}
}
warning("Max iterations reached!")
return(list(beta = old.beta, num.iter = num.iter))
}
# Chunk 8
set.seed(12345)
## Data set 1
n <- 200
p <- 400
X1 <- matrix(rnorm(n*p),n,p)
beta0 <- matrix(rnorm(p),p,1)
y1 <- (runif(n) <= plogis(X1%*%beta0)) + 0
lambda=10
fit.1.naive <- system.time(logistic_ridge_newton(X1, y1, beta0, lambda, method = "smw"))
## Data set 2
p <- 800
X2 <- matrix(rnorm(n*p),n,p)
beta0 <- matrix(rnorm(p),p,1)
y2 <- (runif(n) <= plogis(X2%*%beta0)) + 0
fit.2.naive <- system.time(logistic_ridge_newton(X2, y2, beta0, lambda, method = "naive"))
## Data set 3
p <- 1600
X3 <- matrix(rnorm(n*p),n,p)
beta0 <- matrix(rnorm(p),p,1)
y3 <- (runif(n) <= plogis(X3%*%beta0)) + 0
fit.3.naive <- system.time(logistic_ridge_newton(X3, y3, beta0, lambda, method = "naive"))
## Number of International Calls from Belgium,
## taken from the Belgian Statistical Survey,
## published by the Ministry of Economy,
##
## 73 subjects, 2 variables:
##  Year(x[i])
##  Number of Calls (y[i], in tens of millions)
##
## http://www.uni-koeln.de/themen/statistik/data/rousseeuw/
## Datasets used in Robust Regression and Outlier Detection (Rousseeuw and Leroy, 1986).
## Provided on-line at the University of Cologne.
rm(list=ls())  # clean up workspace
library(xji3ST790)
x <- c(50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
69, 70, 71, 72, 73)
y <- c(0.44, 0.47, 0.47, 0.59, 0.66, 0.73, 0.81, 0.88, 1.06, 1.20, 1.35, 1.49, 1.61,
2.12, 11.90, 12.40, 14.20, 15.90, 18.20, 21.20, 4.30, 2.40, 2.70, 2.90)
epsilon <- 0.25
X <- cbind(rep(1, length(x)), x)
fit.smLAD <- smLAD(X, y)
fit.lm <- lm(y ~ X)
fitted.lm <- fit.lm$fitted.values
fitted.smLAD <- X %*% fit.smLAD$beta
# Now plot the two fitted lines and data
plot(x, y, type = "l", col = "blue", main = "Step 2 plot")
lines(x, fitted.lm, lty = 2, col = "green")
lines(x, fitted.smLAD, lty = 3, col = "red")
legend(x[1], 20,legend = c("Data", "Least Sqaure", "smLAD"),
lty = c(1, 2, 3), col = c("blue", "green", "red"))
library(xji3ST790)
library(xji3ST790)
install.packages("rjags")
library(rjags)
load("/Users/xji3/Downloads/USHCNprcpSetup.RData")
year <- rep(1900:2014, each=365)
temp1 <- PRCP[which(year >= 1950), ]
temp <- PRCP[(50*365 + 1):(115*365), ]
# Construct Yit matrix first
Yit.missing <- NULL
Yit0 <- NULL
for(i in 1:(2014 - 1950 + 1)){
Yit.missing <- rbind(Yit.missing, colSums(is.na(temp[(365*(i-1) + 1):(365*i), ])))
Yit0 <- rbind(Yit0, apply(temp[(365*(i-1) + 1):(365*i), ], 2, max, na.rm = T))
}
Yit0[Yit.missing > 50] <- NA
dim(Yit.missing)
Yit.missing[1:10,1:10]
dim(Yit0)
# Column operations
Yit <- Yit0[, colSums(is.na(Yit0)) < 11]
dim(Yit)
hist(Yit)
Yit0[1, 1:5]
Yit0[1:4, 1:5]
dim(Yit)
Yit[1:4, 1:5]
install.packages("rjags")
library(rjags)
install.packages("rjags")
library(rjags)
###############################################################################################
####
#### ST590-640 Exam 3
#### Author: Yi Zhang
#### Date: May 5, 2017
####
###############################################################################################
rm(list=ls())
library(rjags)
#load("C:/Users/Wang Lab/Documents/NCSU/ST590-Applied Bayesian Analysis/2017Spring/Exams/E3/USHCNprcpSetup.RData")
load("/Users/xji3/Downloads/USHCNprcpSetup.RData")
year <- rep(1900:2014, each=365)
temp1 <- PRCP[which(year >= 1950), ]
temp <- PRCP[(50*365 + 1):(115*365), ]
# Construct Yit matrix first
Yit.missing <- NULL
Yit0 <- NULL
for(i in 1:(2014 - 1950 + 1)){
Yit.missing <- rbind(Yit.missing, colSums(is.na(temp[(365*(i-1) + 1):(365*i), ])))
Yit0 <- rbind(Yit0, apply(temp[(365*(i-1) + 1):(365*i), ], 2, max, na.rm = T))
}
Yit0[Yit.missing > 50] <- NA
dim(Yit.missing)
Yit.missing[1:10,1:10]
dim(Yit0)
# Column operations
Yit <- Yit0[, colSums(is.na(Yit0)) < 11]
dim(Yit)
hist(Yit)
max(Yit)
Ybar <- mean(Yit, na.rm = T)
#for(i in 1:ncol(Yit)){
#  Yit[is.na(Yit[,i]), i] <- round(Ybar)
#}
Yit[,1]
Yit[,2]
Yit[,3]
Yit[,4]
hist(Yit)
hist(log(Yit))
head(Yit)
ls()
plot(lon.lat,axes=FALSE,xlab="",ylab="",main="Monitor locations")
boxplot(Yit,xlab="Stations",ylab="Maximum daily Precipitation",main="Maximum daily Precipitation each year from 1950-2014 by stations")
boxplot(log(Yit),xlab="Stations",ylab="Log of maximum daily Precipitation",main="Log of maximum daily Precipitation each year from 1950-2014 by stations")
boxplot(t(log(Yit)),xlab="Year",ylab="Log of maximum daily Precipitation",main="Log of maximum daily Precipitation each year from 1950-2014 by year")
## JAGS model and convergence diagnostics
nt   <- nrow(Yit)
ns   <- ncol(Yit)
modelstring <- "model{
# Likelihood
for(i in 1:ns){
for(t in 1950:2014){
Yit[i,t] ~ dgamma(a[i, t],b[i,t])
a[i, t] <- (beta1[i] + X[t] * beta2[i])^2/beta3[i]
b[i, t] <- (beta1[i] + X[t] * beta2[i])/beta3[i]
X[t] <- (t-1950)/10
}
}
# Random effects
for(i in 1:ns){
beta1[i] ~ dnorm(0,tau1)
beta2[i] ~ dnorm(0,tau2)
beta3[i] ~ dnorm(0,tau3)
}
# Priors
tau1 ~ dgamma(0.1,0.1)
tau2 ~ dgamma(0.1,0.1)
tau3 ~ dgamma(0.1,0.1)
}"
dat    <- list(Y=log(Yit),ns=ns,nt=nt)
#init   <- list(RE=rep(0,ns))
#init   <- list(mu=Ybar)
model1 <- jags.model(textConnection(modelstring),data = dat, quiet=TRUE, n.chains=1)
finished.pairs <- readLines('../Filtered_pairs.txt')
read.summary.mat <- function(summary_file, col_names){
all <- readLines(summary_file, n = -1)
row.names <- strsplit(all[length(all)], ' ')[[1]][-1]
summary_mat <- as.matrix(read.table(summary_file,
row.names = row.names,
col.names = col_names))
return (summary_mat)
}
rm(list=ls())  # clean up workspace
setwd("/Users/xji3/GitFolders/YeastIGCTract/PSJSAnalyses/")
filtered.pairs <- readLines('../Filtered_pairs.txt')
